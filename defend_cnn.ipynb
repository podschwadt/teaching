{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "defend_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/podschwadt/teaching/blob/master/defend_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCBeUwVp9AS",
        "colab_type": "text"
      },
      "source": [
        "# Defense with adversarial training\n",
        "\n",
        "In this section we will use adversarial training to harden our CNN against adversarial examples. \n",
        "\n",
        "In adversarial training the dataset get \"augmented\" with adversarial examples that are correctly labeled. This way the network learns that such pertubations are possible and can adapt to them. \n",
        "\n",
        "We will be using the IBM Adversarial Robustness Toolbox in this exercise. It offers a very easy-to-use implementation of adversarial training and a number of other defenses. \n",
        "https://github.com/IBM/adversarial-robustness-toolbox\n",
        "\n",
        "\n",
        "We start out by importing most of the modules and functions we will need. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsvgCPv17t3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install adversarial-robustness-toolbox\n",
        "!git clone https://github.com/tensorflow/cleverhans.git\n",
        "!pip install cleverhans/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFCdbXWxp9AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# most of our imports\n",
        "import warnings\n",
        "import numpy as np\n",
        "import os\n",
        "with warnings.catch_warnings():\n",
        "    import keras # keras is still using some deprectade code\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from cleverhans.utils_keras import KerasModelWrapper\n",
        "from cleverhans.attacks import BasicIterativeMethod, FastGradientMethod, CarliniWagnerL2\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from art.classifiers import KerasClassifier\n",
        "\n",
        "\n",
        "# helper code \n",
        "def exract_ones_and_zeroes( data, labels ):\n",
        "    data_zeroes = data[ np.argwhere( labels == 0 ).reshape( -1 ) ][ :200 ]\n",
        "    data_ones = data[ np.argwhere( labels == 1 ).reshape( -1 ) ][ :200 ]\n",
        "    x = np.vstack( (data_zeroes, data_ones) )\n",
        "\n",
        "    x = x / 255.\n",
        "    print( x.shape )\n",
        "\n",
        "    labels_zeroes = np.zeros( data_zeroes.shape[ 0 ] )\n",
        "    labels_ones = np.ones( data_ones.shape[ 0 ] )\n",
        "    y = np.append( labels_zeroes, labels_ones )\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def exract_two_classes( data, labels, classes=(0,1), no_instance=200 ):\n",
        "    data_zeroes = data[ np.argwhere( labels ==  classes[0] ).reshape( -1 ) ][ :no_instance ]\n",
        "    data_ones = data[ np.argwhere( labels == classes[1] ).reshape( -1 ) ][ :no_instance ]\n",
        "    x = np.vstack( (data_zeroes, data_ones) )\n",
        "    \n",
        "    # normalize the data\n",
        "    x = x / 255.\n",
        "\n",
        "    labels_zeroes = np.zeros( data_zeroes.shape[ 0 ] )\n",
        "    labels_ones = np.ones( data_ones.shape[ 0 ] )\n",
        "    y = np.append( labels_zeroes, labels_ones )\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def convert_to_keras_image_format( x_train, x_test ):\n",
        "    if keras.backend.image_data_format( ) == 'channels_first':\n",
        "        x_train = x_train.reshape( x_train.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
        "        x_test = x_test.reshape( x_test.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
        "    else:\n",
        "        x_train = x_train.reshape( x_train.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
        "        x_test = x_test.reshape( x_test.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
        "\n",
        "    return x_train, x_test\n",
        "\n",
        "\n",
        "def mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=2 ):\n",
        "    # define the classifier\n",
        "    clf = keras.Sequential( )\n",
        "    clf.add( Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[ 1: ] ) )\n",
        "    clf.add( Conv2D( 64, (3, 3), activation='relu' ) )\n",
        "    clf.add( MaxPooling2D( pool_size=(2, 2) ) )\n",
        "    clf.add( Dropout( 0.25 ) )\n",
        "    clf.add( Flatten( ) )\n",
        "    clf.add( Dense( 128, activation='relu' ) )\n",
        "    clf.add( Dropout( 0.5 ) )\n",
        "    clf.add( Dense( y_train.shape[ 1 ], activation='softmax' ) )\n",
        "\n",
        "    clf.compile( loss=keras.losses.categorical_crossentropy,\n",
        "                 optimizer='adam',\n",
        "                 metrics=[ 'accuracy' ] )\n",
        "\n",
        "    clf.fit( x_train, y_train,\n",
        "             epochs=epochs,\n",
        "             verbose=1 )\n",
        "    clf.summary( )\n",
        "    score = clf.evaluate( x_test, y_test )\n",
        "    print( 'Test loss:', score[ 0 ] )\n",
        "    print( 'Test accuracy:', score[ 1 ] )\n",
        "\n",
        "    return clf\n",
        "\n",
        "\n",
        "def show_image( img ):\n",
        "    plt.imshow( img.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "    plt.axis( 'off' )\n",
        "    plt.show( )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQb51r9Pp9AY",
        "colab_type": "text"
      },
      "source": [
        "We start out by loading the data, preparing it and training our CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi_KR9mVp9AZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# extract ones and zeroes\n",
        "x_train, y_train = exract_ones_and_zeroes( x_train, y_train )\n",
        "x_test, y_test = exract_ones_and_zeroes( x_test, y_test )\n",
        "\n",
        "# we need to bring the data in to a format that our cnn likes\n",
        "y_train = keras.utils.to_categorical( y_train, 2 )\n",
        "y_test = keras.utils.to_categorical( y_test, 2 )\n",
        "\n",
        "# convert it to a format keras can work with\n",
        "x_train, x_test = convert_to_keras_image_format(x_train, x_test)\n",
        "\n",
        "# need to some setup so everything gets excturted in the same tensorflow session\n",
        "session = tf.Session( )\n",
        "keras.backend.set_session( session )\n",
        "\n",
        "# get and train our cnn\n",
        "clf = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No-xgwJAp9Ae",
        "colab_type": "text"
      },
      "source": [
        "We want to know how robust our model is against an attack. To do this we are calculating the `empirical robustness`. This is equivalent to computing the minimal perturbation that the attacker must introduce for a    successful attack. We are following the approach of Moosavi-Dezfooli et al. 2016 (paper link: https://arxiv.org/abs/1511.04599).\n",
        "\n",
        "The emperical robustness method supports two attacks at the moment. \n",
        "The `Fast Gradient Sign Method` and `Hop Skip and Jump`.\n",
        "\n",
        "You can use them by passing either `fgsm` or `hsj` as parameters.\n",
        "The default attack parameters are the following:\n",
        "```\n",
        "    \"fgsm\":{\"eps_step\": 0.1, \"eps_max\": 1., \"clip_min\": 0., \"clip_max\": 1.},\n",
        "    \"hsj\" {'max_iter': 50, 'max_eval': 10000, 'init_eval': 100, 'init_size': 100}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGO_xXwHp9Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from art.metrics import empirical_robustness\n",
        "\n",
        "# wrap the model an calculte emperical robustnees\n",
        "wrapper = KerasClassifier( model=clf, clip_values=(0., 1.) )\n",
        "print( 'robustness of the undefended model', \n",
        "      empirical_robustness( wrapper, x_test, 'fgsm'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHoKCGrJWtIy",
        "colab_type": "text"
      },
      "source": [
        "Try different attack parameters and compare the results. \n",
        "\n",
        "Tip:\n",
        "\n",
        "For `hsj` use only a few examples otherwise it will take forever."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqNgpmoIWNTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### your code goes here\n",
        "x_small = x_test[ :10 ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkJT6D_p9Ai",
        "colab_type": "text"
      },
      "source": [
        "Let's create an adversarial example and see how it looks.\n",
        "We want to know how to the model performs on adversarial exampels. Let's create adversarial examples out of the training set and see how the model does with it.\n",
        "\n",
        "Below you can the keyword arguments for the attack\n",
        "\n",
        "```\n",
        "norm=np.inf, eps=.3, eps_step=0.1, targeted=False, num_random_init=0, batch_size=1, minimal=False\n",
        "        \"\"\"\n",
        "        :param norm: The norm of the adversarial perturbation. Possible values: np.inf, 1 or 2.\n",
        "        :param eps: Attack step size (input variation)\n",
        "        :param eps_step: Step size of input variation for minimal perturbation computation\n",
        "        :param targeted: Indicates whether the attack is targeted (True) or untargeted (False)\n",
        "        :param num_random_init: Number of random initialisations within the epsilon ball. For random_init=0 starting at\n",
        "            the original input.\n",
        "        :param batch_size: Size of the batch on which adversarial samples are generated.\n",
        "        :param minimal: Indicates if computing the minimal perturbation (True). If True, also define `eps_step` for\n",
        "                        the step size and eps for the maximum perturbation.\n",
        "   \n",
        "```\n",
        "\n",
        "Find good parameters for the attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-anGrCjjp9Aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an adversarial example with fgsm and plot it\n",
        "from art.attacks import FastGradientMethod\n",
        "fgsm = FastGradientMethod( wrapper )\n",
        "x_adv = fgsm.generate( x_test[ 0 ].reshape( (1,28,28,1) ) )\n",
        "# prediction for the adversarial example\n",
        "\n",
        "# show the adverarial example\n",
        "show_image( x_adv )\n",
        "\n",
        "# create adversarial examples for the all of the set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhEY7Iagp9Aw",
        "colab_type": "text"
      },
      "source": [
        "## Adversarial Training\n",
        "\n",
        "Let's create a new untrained model with the same architecture that we have been using so far. \n",
        "\n",
        "We will train the model using adversarial training framework. The idea is very simple:\n",
        "\n",
        "1.   Train the model for 1 epoch\n",
        "2.   Create adversarial examples using FGSM \n",
        "3.   Enhance training data by mixing it with the adversarial examples. (Only mix in the adversarial examples created in this iteartion)\n",
        "4.   Goto 1\n",
        "\n",
        "We will be using the FGSM attack from `art` this time.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfHrX6WftGOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new untrained model and wrap it\n",
        "new_model = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=0 )\n",
        "defended_model = KerasClassifier(clip_values=(0,1), model=new_model )\n",
        "# define the attack we are using\n",
        "fgsm = FastGradientMethod( defended_model, eps=.3 )\n",
        "\n",
        "# parameters\n",
        "epochs = 5 # number of iterations that we will perform training for\n",
        "ratio = .5  # ratio of the test set that will get turned into adversarial examples\n",
        "            # each iteration\n",
        "\n",
        "\n",
        "# some helpers\n",
        "idx = np.arange( x_train.shape[ 0 ], dtype=np.int )\n",
        "\n",
        "# create varialbes to hold the training data.\n",
        "# for now it is just the normal training data. we'll mix in the \n",
        "# adversarial examples in later\n",
        "x_train_enhanced = x_train\n",
        "y_train_enhanced = y_train\n",
        "\n",
        "\n",
        "for i in range( epochs ):\n",
        "  # train model for one epoch\n",
        "\n",
        "  # shuffle   \n",
        "\n",
        "  # pick the subest of the train data to turn into adverarial examples\n",
        "\n",
        "\n",
        "  # create adversarial examples\n",
        "\n",
        "  # add the adversarial examples to the training data\n",
        "\n",
        "\n",
        "# training is done. let's evaulate the performance on the test set \n",
        "# and adversarial examples\n",
        "acc = defended_model._model.evaluate( x_test, y_test )[ 1 ]\n",
        "print( 'acc on the test data: ', acc )\n",
        "\n",
        "# and now on adversarial examples\n",
        "x_test_adv = fgsm.generate( x_test )\n",
        "acc =  wrapper._model.evaluate( x_test_adv, y_test )\n",
        "print( 'accuracy on adversarial examples: ', acc )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhTCRfbCr6iq",
        "colab_type": "text"
      },
      "source": [
        "To use the adversarial training that comes with `art` we need to pass our wrapped model to an `AdversarialTrainer` instance. The `AdversarialTrainer` also needs an instance of the attack that will be used to create the adversarial examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxQZLbgBp9Ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from art.defences import AdversarialTrainer\n",
        "\n",
        "# get a new untrained model and warp it\n",
        "new_model = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=0 )\n",
        "defended_model = KerasClassifier(clip_values=(0,1), model=new_model )\n",
        "# define the attack we are using\n",
        "fgsm = FastGradientMethod( defended_model )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3geBOs1p9A4",
        "colab_type": "text"
      },
      "source": [
        "Create the `AdversarialTrainer` instance. \n",
        "Train the model and evaluate it on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BWvgxNtp9A6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the adversarial trainer and train the new network\n",
        "adversarial_tranier = AdversarialTrainer( defended_model, fgsm )\n",
        "adversarial_tranier.fit( x_train, y_train, batch_size=100, nb_epochs=5 )\n",
        "\n",
        "# evaluate how good our model is\n",
        "defended_model._model.evaluate( x_test,y_test )\n",
        "\n",
        "# and now on adversarial examples\n",
        "x_test_adv = fgsm.generate( x_test )\n",
        "acc =  wrapper._model.evaluate( x_test_adv, y_test )\n",
        "print( 'accuracy on adversarial examples: ', acc )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV0kBz2Fp9BA",
        "colab_type": "text"
      },
      "source": [
        "Calculate the `empirical robustness` for our now hopefully more robust model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7CROH1Gp9BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the empiracal robustness\n",
        "print( 'robustness of the defended model', \n",
        "      empirical_robustness( defended_model, x_test[0:], 'fgsm', {}) )\n",
        "x_adv = fgsm.generate(x_test[0].reshape((1,28,28,1) ))\n",
        "print( 'class prediction for the adversarial sample:',\n",
        "       clf.predict( x_adv.reshape((1,28,28,1) ) ) \n",
        "     )\n",
        "plt.imshow( x_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d2J443nA9k8",
        "colab_type": "text"
      },
      "source": [
        "# Black box attacks\n",
        "\n",
        "Assume we do not have access to the internal workings of our target model. This means we can not easily calculate gradients.\n",
        "Fortunatley or unfortunatle depending on how you are looking at it adversarial exampels created on one model can be also used against a different model. Given their learned descion boundary is similar enough. \n",
        "\n",
        "We do not know what the target model looks like but in most cases we no the domain that it works in, MNIST in our case, so we can make an educated guess. We then train our model with the architecture that we guessed and create adversarial examples using this model. If our model and the target model are similare enough the adversarial examples can be transferd.\n",
        "\n",
        "\n",
        "In the code below we will be training two different models and see if the adversarial examples transfer from one to the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay5X8686uwA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras.backend as k\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Reshape\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# extract ones and zeroes\n",
        "x_train, y_train = exract_ones_and_zeroes( x_train, y_train )\n",
        "x_test, y_test = exract_ones_and_zeroes( x_test, y_test )\n",
        "\n",
        "# we need to bring the data in to a format that our cnn likes\n",
        "y_train = keras.utils.to_categorical( y_train, 2 )\n",
        "y_test = keras.utils.to_categorical( y_test, 2 )\n",
        "\n",
        "# convert it to a format keras can work with\n",
        "x_train, x_test = convert_to_keras_image_format(x_train, x_test)\n",
        "\n",
        "# Create simple CNN\n",
        "model_0 = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=5 )\n",
        "print( model_0.evaluate( x_test, y_test )[ 1 ] )\n",
        "# create a simple DNN and train it\n",
        "\n",
        "\n",
        "# compare how the models do on the test set\n",
        "\n",
        "\n",
        "\n",
        "# compare how the models perform on adversarial examples\n",
        "\n",
        "\n",
        "\n",
        "# let's see how the models do when we give them the adversarial examples \n",
        "# created against the other model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzIPPxrxOKFA",
        "colab_type": "text"
      },
      "source": [
        "We do not always have access to the same training data though. We can collect our own data and use the victim model to label the data. \n",
        "\n",
        "Using `model_0` from the cell above as the victim model in a black box setting train you own substitue model on the training data provided in the cell below. Pick an architecture that you think will work well or that you are interested in trying. The paper desrcibing the attack can be found here: https://arxiv.org/abs/1602.02697\n",
        "\n",
        "Hint: `cleverhans` provides a few helpful functions for performing the data augmentation.\n",
        "\n",
        " Also try the transferability of attacks other than FGSM. Hint: Don't use the too much data for more complex attacks or it will take a long time. Start with a smaller subset first to get a feeling how long it takes to generate advesarial examples.\n",
        "\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNXPkTWLRi1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up black box. should already be trained. if not run the cell above first.\n",
        "black_box = model_0\n",
        "\n",
        "# load data that is differen from the data that black box has been trained on.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# extract ones and zeroes\n",
        "x_train, y_train = exract_two_classes( x_train, y_train, no_instance=400 )\n",
        "x_test, y_test = exract_two_classes( x_test, y_test, no_instance=400 )\n",
        "\n",
        "# pick few instances from the training data\n",
        "x_train = x_train[ [0,1, 199, 200] ]\n",
        "y_train = y_train[ [0,1, 199, 200] ]\n",
        "# we need to bring the data in to a format that our cnn likes\n",
        "y_train = keras.utils.to_categorical( y_train, 2 )\n",
        "y_test = keras.utils.to_categorical( y_test, 2 )\n",
        "print( x_train.shape )\n",
        "# convert it to a format keras can work with\n",
        "x_train, x_test = convert_to_keras_image_format(x_train, x_test)\n",
        "print( x_train.shape )\n",
        "\n",
        "# use the black box classifier to create labes for the training data\n",
        "\n",
        "# define subsitute model\n",
        "\n",
        "# create computational graph for data augmentation\n",
        "\n",
        "# train your own substitute  model\n",
        "\n",
        "  # train for a few epochs\n",
        "\n",
        "  # perform data augmentation\n",
        "\n",
        "    # get labels for new data\n",
        "\n",
        "\n",
        "# create adverasarial examples on the substitute model\n",
        "sub_wrapper = KerasClassifier(clip_values=(0,1), model=sub )\n",
        "# define the attack we are using\n",
        "fgsm = FastGradientMethod( sub )\n",
        "x_adv = fgsm.generate( x_test )\n",
        "\n",
        "# evaluate performance on adversarial exampales for the substitute model and the black box\n",
        "black_box.evaluate( x_adv, y_test )\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}