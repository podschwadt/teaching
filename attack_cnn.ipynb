{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attack_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/podschwadt/teaching/blob/master/attack_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1IIenRzV7Gv",
        "colab_type": "text"
      },
      "source": [
        "# Attacking a CNN\n",
        "\n",
        "In this exercise we will train a CNN to distinguish between instances of handwritten `0` and instances of handwritten `1`. We will be using `keras` to do this.  \n",
        "\n",
        "Once we have a trained classifier, we will be using `cleverhans` to create adversarial examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhoEjgYmWJ0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install cleverhans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIH4d-w4V7G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import os\n",
        "with warnings.catch_warnings():\n",
        "    import keras # keras is still using some deprectade code\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from cleverhans.utils_keras import KerasModelWrapper\n",
        "from cleverhans.attacks import BasicIterativeMethod, FastGradientMethod, CarliniWagnerL2\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIL2ziyzV7G_",
        "colab_type": "text"
      },
      "source": [
        "The MNIST dataset contains data for all of the digits, but for now we are only interested in 1s and 0s. Therefore we are extracting only those from the dataset. \n",
        "\n",
        "We also need to normalize the data. This means that whatever interval was previously covered by the input values will be squashed to `[0,1]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMKzVNfRV7HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exract_two_classes( data, labels, classes=(0,1), no_instance=200 ):\n",
        "    data_zeroes = data[ np.argwhere( labels ==  classes[0] ).reshape( -1 ) ][ :no_instance ]\n",
        "    data_ones = data[ np.argwhere( labels == classes[1] ).reshape( -1 ) ][ :no_instance ]\n",
        "    x = np.vstack( (data_zeroes, data_ones) )\n",
        "    \n",
        "    # normalize the data\n",
        "    x = x / 255.\n",
        "\n",
        "    labels_zeroes = np.zeros( data_zeroes.shape[ 0 ] )\n",
        "    labels_ones = np.ones( data_ones.shape[ 0 ] )\n",
        "    y = np.append( labels_zeroes, labels_ones )\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3nYU03lV7HD",
        "colab_type": "text"
      },
      "source": [
        "Load the actual data and use our preprocessing function from earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWwost07V7HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "# extract ones and zeroes\n",
        "x_train, y_train = exract_two_classes( x_train, y_train )\n",
        "x_test, y_test = exract_two_classes( x_test, y_test )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APCk9NzFV7HL",
        "colab_type": "text"
      },
      "source": [
        "Keras expects the image to have a color channel. We need to add another dimension to our image to represent\n",
        "that color channel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwJNnnMBV7HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need to bring the data in to a format that our cnn likes\n",
        "y_train = keras.utils.to_categorical( y_train, 2 )\n",
        "y_test = keras.utils.to_categorical( y_test, 2 )\n",
        "\n",
        "if keras.backend.image_data_format( ) == 'channels_first':\n",
        "    x_train = x_train.reshape( x_train.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
        "    x_test = x_test.reshape( x_test.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
        "    input_shape = (1, x_train.shape[ 1 ], x_train.shape[ 2 ])\n",
        "else:\n",
        "    x_train = x_train.reshape( x_train.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
        "    x_test = x_test.reshape( x_test.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
        "    input_shape = (x_train.shape[ 1 ], x_train.shape[ 2 ], 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_e_aMgDV7HQ",
        "colab_type": "text"
      },
      "source": [
        "We need to make sure that `cleverhans` has access to our model graph. To do this we make sure that `keras` uses the same `tensorflow` session that `cleverhans` will be using. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flvawc_hV7HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to some setup so everything gets excecuted in the same tensorflow session\n",
        "session = tf.Session( )\n",
        "keras.backend.set_session( session )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d64xNkKdV7HX",
        "colab_type": "text"
      },
      "source": [
        "We are using a very simple CNN. For our two output classes this is probably overkill. This network can be used to distinguish between all 10 classes with very high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMjW64ADV7HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the classifier\n",
        "clf = keras.Sequential( )\n",
        "clf.add( Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=input_shape ) )\n",
        "clf.add( Conv2D( 64, (3, 3), activation='relu' ) )\n",
        "clf.add( MaxPooling2D( pool_size=(2, 2) ) )\n",
        "clf.add( Dropout( 0.25 ) )\n",
        "clf.add( Flatten( ) )\n",
        "clf.add( Dense( 128, activation='relu' ) )\n",
        "clf.add( Dropout( 0.5 ) )\n",
        "clf.add( Dense( 2, activation='softmax' ) )\n",
        "\n",
        "clf.compile( loss=keras.losses.categorical_crossentropy,\n",
        "             optimizer='adam',\n",
        "             metrics=[ 'accuracy' ] )\n",
        "\n",
        "clf.fit( x_train, y_train,\n",
        "         epochs=16,\n",
        "         verbose=0 )\n",
        "#clf.summary( )\n",
        "score = clf.evaluate( x_test, y_test, verbose=0 )\n",
        "print( 'Test loss:', score[ 0 ] )\n",
        "print( 'Test accuracy:', score[ 1 ] )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn0dNIotIQ_n",
        "colab_type": "text"
      },
      "source": [
        "Let's get to the actual attack magic. First we are picking a sample that we want to perturbate. After that we will be implementing our own FGSM attack. We will make use of the `KerasModelWrapper` from `cleverhans`. Which offers a few convience functions like obtaining the `logits` layer easily.\n",
        "\n",
        "\n",
        "The attack is fairly simple. It consists of the following steps: \n",
        "\n",
        "1.   Compute the loss of the original sample\n",
        "2.   Calculate the gradient of the loss wrt the input \n",
        "3.   Take the sign of the gradient and add a fraction episilon to the input.\n",
        "\n",
        "Epsilon controlls the strenght of the pertubation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RovKr9sKIQgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.compat import softmax_cross_entropy_with_logits\n",
        "\n",
        "#chose a sample to pertubate\n",
        "sample_ind = 100 # chosen by totaly random dice roll\n",
        "\n",
        "# picking a test sample\n",
        "sample = x_test[ sample_ind, : ]\n",
        "\n",
        "print( sample.shape )\n",
        "\n",
        "# plot the first instance in the traning set\n",
        "plt.imshow( sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n",
        "\n",
        "# constructing adversarial examples\n",
        "print( 'class prediction for the test samples:',\n",
        "       clf.predict( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ) )\n",
        "# setup the attack\n",
        "wrapper = KerasModelWrapper( clf )\n",
        "eps = 1. # allowed maximum modification\n",
        "\n",
        "# setup the compuation graph\n",
        "x = clf.layers[ 0 ].input\n",
        "y = tf.placeholder( tf.float32, shape=y_test[ sample_ind, : ].shape )\n",
        "logits = wrapper.get_logits( x )\n",
        "\n",
        "# compute the loss of our original sample\n",
        "loss = softmax_cross_entropy_with_logits( labels=y, logits=logits )\n",
        "\n",
        "# get the gradient wrt to the input.\n",
        "gradient = tf.gradients( loss, x )\n",
        "\n",
        "# calculate the pertubation\n",
        "pertubation = tf.sign( gradient )\n",
        "pertubation = tf.stop_gradient( pertubation )\n",
        "\n",
        "# apply pertubation\n",
        "x_adv = x + pertubation * eps\n",
        "\n",
        "# now that we have the graph set up we need to run it\n",
        "\n",
        "#get the correct label\n",
        "true_label = y_test[ sample_ind, : ]\n",
        "\n",
        "# execute the graph\n",
        "adversarial_sample = session.run( [ x_adv ], \n",
        "                                 feed_dict={ x: sample.reshape( 1, sample.shape[ 0 ], \n",
        "                                                               sample.shape[ 1 ], \n",
        "                                                               sample.shape[ 2 ] )\n",
        "                                            , y: true_label  } )[ 0 ][ 0 ] # it returns a list\n",
        "                                                                           # wich contains a number\n",
        "                                                                           # of instances\n",
        "\n",
        "print( 'our adversarial example' )\n",
        "print( adversarial_sample.shape )\n",
        "print( 'class prediction for our sample:', clf.predict( adversarial_sample ) )  \n",
        "plt.imshow( adversarial_sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azepEwpTewML",
        "colab_type": "text"
      },
      "source": [
        "The FGSM is one of the most simple attacks. As we can see that results are not very convincing. We can improve on it by making it iterative. \n",
        "\n",
        "Using the code from above, create an iterative version of FGSM that calculates a new pertubation for ever iteration and stops once it achieve misclassifaction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOHo8eQ0gS4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VszDZ1p6V7Hc",
        "colab_type": "text"
      },
      "source": [
        "Let's get to the actual attack magic. First we are picking a sample that we want to perturbate. After selecting the sample, we will use the FGSM attack and the Carlini & Wagner L2 attack to perturbate it into an adversarial example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrbyOs_3V7He",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using the ceverhans implemenation\n",
        "fgm = FastGradientMethod( wrapper, sess=session )\n",
        "eps = 1.0 # allowed maximum modification\n",
        "\n",
        "# excetute the attack\n",
        "with warnings.catch_warnings():\n",
        "    modified_sample = fgm.generate_np( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ),\n",
        "                                   **{ 'eps': eps } )\n",
        "\n",
        "print( 'class prediction for the modified test samples:',\n",
        "       clf.predict( modified_sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ) )\n",
        "plt.imshow( modified_sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n",
        "\n",
        "params = { 'binary_search_steps': 1,\n",
        "            'max_iterations': 100,\n",
        "            'learning_rate': .2,\n",
        "            'initial_const': 10 }\n",
        "\n",
        "# let's try a stronger attack\n",
        "with warnings.catch_warnings():\n",
        "    cw_l2 = CarliniWagnerL2( wrapper, sess=session )\n",
        "    modified_sample = cw_l2.generate_np( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) )\n",
        "\n",
        "print( 'class prediction for the cw modified test samples:',\n",
        "       clf.predict( modified_sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ) )\n",
        "plt.imshow( modified_sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKJQIF24Y91W",
        "colab_type": "text"
      },
      "source": [
        "We have seen that FGSM does not do a great job of producing adversarial examples when work with 0 and 1. Update the code above work on all 10 digits and try for a number of 0 instance what class they get transformed into in an untargeted attack.\n",
        "Alternativley pick a pair of numbers that you think are closer to each orther and the FGSM attack should work better with.\n",
        "\n",
        "\n",
        "`cleverhans` provides more attacks than the once introdcued above. Try the JSM attack or virtual adversary.\n",
        "\n",
        "You can find more information on the attacks here: https://github.com/tensorflow/cleverhans/tree/master/cleverhans/attacks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvZ3hfrNcp9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}